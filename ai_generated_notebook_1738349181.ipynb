{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3add1144",
   "metadata": {},
   "source": [
    "Okay, here's a Jupyter Notebook structure, which you can copy and paste into a new `.ipynb` file. It will contain a simple neural network example, explanations, and code, all properly formatted.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6338dc",
   "metadata": {},
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Simple Neural Network Training Example\\n\",\n",
    "    \"\\n\",\n",
    "    \"This notebook demonstrates how to train a basic neural network using TensorFlow/Keras. We'll use a simple classification task as an example.\\n\",\n",
    "    \"\\n\",\n",
    "    \"**Here's the plan:**\\n\",\n",
    "    \"1. **Import Libraries:** Import the necessary libraries (TensorFlow, NumPy).\\n\",\n",
    "    \"2. **Generate Data:** Create synthetic data for training and testing.\\n\",\n",
    "    \"3. **Build Model:** Define a simple neural network architecture.\\n\",\n",
    "    \"4. **Compile Model:** Configure the optimizer, loss function, and metrics.\\n\",\n",
    "    \"5. **Train Model:** Train the model using the generated data.\\n\",\n",
    "    \"6. **Evaluate Model:** Evaluate the model's performance on test data.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 1. Import Libraries\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"import tensorflow as tf\\n\",\n",
    "    \"import numpy as np\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 2. Generate Data\\n\",\n",
    "    \"\\n\",\n",
    "    \"We'll generate some simple 2D data points with two classes. The data will be distributed in two clusters.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"def generate_data(num_samples=1000):\\n\",\n",
    "    \"    # Generate random points in two clusters\\n\",\n",
    "    \"    cluster1_x = np.random.normal(2, 1, num_samples//2)\\n\",\n",
    "    \"    cluster1_y = np.random.normal(2, 1, num_samples//2)\\n\",\n",
    "    \"    cluster2_x = np.random.normal(7, 1, num_samples//2)\\n\",\n",
    "    \"    cluster2_y = np.random.normal(7, 1, num_samples//2)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    x_data = np.concatenate((cluster1_x, cluster2_x), axis=0)\\n\",\n",
    "    \"    y_data = np.concatenate((cluster1_y, cluster2_y), axis=0)\\n\",\n",
    "    \"    features = np.column_stack((x_data, y_data))\\n\",\n",
    "    \"\\n\",\n",
    "    \"    # Create labels (0 for cluster 1, 1 for cluster 2)\\n\",\n",
    "    \"    labels = np.concatenate((np.zeros(num_samples//2), np.ones(num_samples//2)), axis=0)\\n\",\n",
    "    \"    return features.astype('float32'), labels.astype('int32')\\n\",\n",
    "    \"\\n\",\n",
    "    \"features, labels = generate_data()\\n\",\n",
    "    \"print(\\\"Data shape:\\\", features.shape)\\n\",\n",
    "    \"print(\\\"Label shape:\\\", labels.shape)\\n\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 3. Build Model\\n\",\n",
    "    \"\\n\",\n",
    "    \"Here we will create a simple Sequential model with two layers:\\n\",\n",
    "    \"  * An input layer to receive features and then process into a hidden layer with relu activation.\\n\",\n",
    "    \"  * A output layer for making a classification decision (sigmoid activation)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"model = tf.keras.models.Sequential([\\n\",\n",
    "    \"  tf.keras.layers.Dense(units=16, activation='relu', input_shape=(2,)),  # Input layer and hidden layer\\n\",\n",
    "    \"  tf.keras.layers.Dense(units=1, activation='sigmoid') # Output layer (binary classification)\\n\",\n",
    "    \"])\\n\",\n",
    "    \"\\n\",\n",
    "    \"model.summary()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 4. Compile Model\\n\",\n",
    "    \"\\n\",\n",
    "    \"We need to define how the model will be trained:\\n\",\n",
    "    \"  - An *optimizer* to adjust the internal weights to reduce loss,\\n\",\n",
    "    \"  - A *loss function* to calculate the error/loss of model prediction,\\n\",\n",
    "    \"  - And *metrics* to evaluate the performance of model during training.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"model.compile(optimizer='adam',\\n\",\n",
    "    \"              loss='binary_crossentropy',\\n\",\n",
    "    \"              metrics=['accuracy'])\\n\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 5. Train Model\\n\",\n",
    "    \"\\n\",\n",
    "    \"Now, we will train the model with the data generated. We'll use 100 epochs.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"history = model.fit(features, labels, epochs=100, verbose=0)\\n\",\n",
    "    \"print(\\\"Training complete\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 6. Evaluate Model\\n\",\n",
    "    \"\\n\",\n",
    "    \"Finally, we'll evaluate the model on the same data (in a real scenario, you would have a separate test set).\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"loss, accuracy = model.evaluate(features, labels, verbose=0)\\n\",\n",
    "    \"print(f'Loss: {loss:.4f}')\\n\",\n",
    "    \"print(f'Accuracy: {accuracy*100:.2f}%')\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"That's it! You've trained a very simple neural network. You can experiment with the model architecture, training parameters, or data to understand how different parameters affect training.\"\n",
    "   ]\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"Python 3\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"python3\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"codemirror_mode\": {\n",
    "    \"name\": \"ipython\",\n",
    "    \"version\": 3\n",
    "   },\n",
    "   \"file_extension\": \".py\",\n",
    "   \"mimetype\": \"text/x-python\",\n",
    "   \"name\": \"python\",\n",
    "   \"nbconvert_exporter\": \"python\",\n",
    "   \"pygments_lexer\": \"ipython3\",\n",
    "   \"version\": \"3.9.13\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 5\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5bda5e8",
   "metadata": {},
   "source": [
    "\n",
    "**How to use this:**\n",
    "\n",
    "1.  **Copy the JSON:** Copy the entire JSON code above.\n",
    "2.  **Create a New Notebook:** In your Jupyter environment (Jupyter Notebook, JupyterLab, etc.), create a new notebook.\n",
    "3.  **Open Notebook as Text Editor:** In Jupyter Notebook (or equivalent in other environments), go to File > Open > (Navigate to your new file)  and select it.  Then make sure that you have selected to open the file as a \"Text Editor\".\n",
    "4.  **Paste JSON:** Paste the copied JSON into the text editor and save it. Jupyter should then open it as a proper notebook.\n",
    "5.  **Run Cells:** Run the cells one by one. You'll see the outputs and be able to modify the code.\n",
    "\n",
    "This should provide you with a working Jupyter Notebook ready for you to learn and experiment with simple neural network training. Let me know if you have more questions.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {}
 },
 "nbformat": 4,
 "nbformat_minor": 5
}